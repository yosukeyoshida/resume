# 職務経歴書

## 基本情報
|key|value|
|---|-----|
|Name|吉田 陽祐|
|GitHub|[yosukeyoshida](https://github.com/yosukeyoshida)|
|LinkedIn|[Yosuke Yoshida](https://www.linkedin.com/in/yosuke-yoshida-)|
|YOUTRUST|[Yosuke Yoshida](https://youtrust.jp/users/acfd39b0eba54a0a37895320604de143)|
|Kaggle|[yosukey](https://www.kaggle.com/yosukey)|

## 学歴・職歴

|年月|学歴・職歴|
|---|-----|
|2008.03|東京工業大学工学部経営システム工学科 卒業|
|2008.04|株式会社ベネフィット・ワン 入社|
|2014.06|株式会社ベネフィット・ワン 退社|
|2014.08|iemo株式会社 入社|
|2017.06|iemo株式会社 退社|
|2017.07|株式会社フリークアウト・ホールディングス 入社 (株式会社カンム出向)|
|2019.01|株式会社フリークアウト・ホールディングス 退社 (株式会社カンム転籍)|
|2019.01|株式会社カンム 入社|
|2022.03|株式会社カンム 退社|
|2022.03|株式会社LayerX 入社|

## 職務経歴
### 株式会社LayerX (2022.03 - 現在)
```
ML, OCR開発
```
https://tech.layerx.co.jp/archive/author/yossylx


### 株式会社カンム (2017.07 - 2022.03)
```
Visaプリペイドカード 「バンドルカード」 のバックエンドや機械学習を活用した機能開発に従事
```

#### 決済システム内製化
##### 背景/課題
* バンドルカードとはアプリから発行できるVisaプリペイドカード https://vandle.jp/
* サービス開始からカード発行, 決済, 残高管理といったバンドルカードの主要な機能は外部のSaaSを利用していたが、自社でコントロールすることのできない仕様や障害の発生、トランザクションの増加に伴うコスト増が問題となってきていた
* 決済システムを内製化することでコスト削減とシステムの安定化、プロダクトの改善を図る

##### 担当
* バンドルカードアプリと通信するAPIサーバ(以下バンドルAPI)からリクエストを受け、カード発行やチャージ, 決済通知等を担うAPIサーバの技術選定から実装まですべてを担当
* Visaの電文を処理するサーバとの間の決済情報の連携
* バンドルAPIのSaaS接続部分の内製化への切り替えに伴う改修

##### 実績
* 既存のバンドルAPIのコードからカードまわりのすべての処理を洗い出しシーケンス図, 状態遷移図の作成
* カード発行やチャージ, 決済通知等を担うAPIサーバの開発
    * バンドルAPIからリクエストを受け以下の処理を行う
        * カード発行, 上位のカードへのアップグレード
        * チャージ, 手数料徴収
        * カードのステータス更新
    * 決済時にバンドルAPIに決済情報を通知
        * Visaの電文を処理するサーバとジョブキューを介して非同期に決済情報を連携し、バンドルAPIに通知を行う
    * JSON Schema / OpenAPIによるスキーマ駆動開発
        * バリデーションやルーティング, HTTPリクエスト/レスポンスの構造体などスキーマから自動生成
* バンドルAPIの改修
    * カードまわりのAPIやバッチ処理を内製化にあわせて改修
    * サーバ同様APIスキーマからAPIクライアントのコードを自動生成
    
##### 工夫した点
* REST APIのスキーマ定義を初期はJSON Schemaを採用し、リリース後しばらくしてからOpenAPIへ移行した
    * 技術選定時点ではJSON Schemaと比較してOpenAPI v2には以下のようなデメリットがあった
        * 決済通知のようなWebhookを記述することができない
        * oneOf, anyOfのような表現が使えない
    * 上記の理由から開発初期の段階ではJSON Schemaを採用した
        * HTTPリクエストのバリデーションにはgojsonschemaを採用したが、各エンドポイントのバリデーションのためにJSON Schemaをそのまま使うことはできなかったのでJSON Schemaをパースして各エンドポイントのバリデーション定義を自動生成するツールを自作
    * その後OpenAPI v3ではCallback, oneOfが追加されたこと、v3対応のバリデーション等の周辺ライブラリが充実してきたこともありOpenAPIに移行した
* 冪等性の考慮
    * 分散トランザクションの考慮が甘くリトライ時の多重実行の懸念がある箇所はリクエストパラメータに一意なキー(Idempotency Key)を付加して冪等性を担保するように改修

##### 技術
* Go
* PostgreSQL
* OpenAPI
* JSON Schema

#### ポチっとチャージ (後払いチャージ)
##### 背景/課題
* ポチっとチャージとはアプリからすぐにチャージができて翌月末までに返済すればよいという後払いサービス
    * それまでのバンドルカードは買い物に使う前にコンビニやペイジーなど事前にチャージが必要であった
    * ちょっとお金が足りなかったり、いますぐ欲しいのにコンビニまで行くのが手間といった問題を解消する機能
    * 本人確認不要で氏名, 生年月日, メールアドレス, 電話番号を登録するだけで利用可能
* バンドルカード事業の収益の柱としたい

##### 担当
* ポチっとチャージの立ち上げとグロース
* 何を作るべきか, 優先順位をどうするか考え実行
* バックエンドと機械学習の開発すべてを担当

##### 実績
* 後払いチャージ機能のバックエンド開発
    * 後払いチャージ機能
        * 氏名, 生年月日, メールアドレス, 電話番号を入力し審査後に残高へチャージ
    * 支払い機能
        * コンビニ, ネット銀行, ペイジー等PSPを利用した支払い
    * ユーザ毎の申込み可能額の算出
        * ルールベースや機械学習モデルを利用したスコアリング
    * 機械学習モデルとのインテグレーション
    * 返済期限超過による督促や機能制限
        * メール, SMS, Pushを用いた督促
        * IVRによる自動架電システムの構築
            * 自動音声によるガイダンスとCSへの転送
    * 不正検知
        * 複数アカウントの検知 etc
* 機械学習モデルの開発
    * 解くべき課題の定義と事業に紐づく評価指標の設計
    * 特徴量エンジニアリング及び機械学習モデルの開発
        * 教師あり二値分類
* 推論APIサーバの構築とバンドルAPIとのインテグレーション
* 機械学習パイプラインの構築
    * Digdag/Embulkを用いてRDSからBigQueryへのデータの転送
    * Cloud Dataflowを用いた前処理とデータセットの作成
    * SageMakerを用いたモデルのトレーニング, サービング
    * Step Functionsを用いてモデルの学習からデプロイまでの自動化
    * 詳細はこちらのブログ記事参照
        * https://tech.kanmu.co.jp/entry/2021/06/11/120953
* 提携企業とのファイル連携, バッチ処理開発
    * 提携企業との要件定義, 業務設計, テストやスケジュール調整といったPM業務からファイル連携やバッチ処理の開発まで担当
    
##### 工夫した点
* サービス開始から1年近くは機械学習を使わずに機能改善やルールベースによるスコアリングの改善によってKPIを伸ばすことだけを考えた
    * ポチっとチャージのバックエンドの開発は自分一人で行っていたので機能改善と機械学習モデルの開発を並行して行うことは困難であったことと、その期間は機能やルールベース改善だけでも大きく事業を成長させることが可能だったので不確実性の高い機械学習に手を出すよりも確度の高い改善の手数を多く打つことを優先した
* しかし以下の問題が顕著になってきたところで一度機能改善の手を止めてでも機械学習を導入することにした
    * ルールベースのロジックが複雑化し保守性の低下, バグの温床となる
    * ユーザの行動に即した多様なデータを活用して柔軟なスコアリングを行いたいがルールベースでは実装が困難
    * KPIの成長が鈍化、事業の状況に合わせた複数のKPIのコントロールが難しい
* 機械学習の導入によって上記問題に対して以下のように改善
    * ルールベースから機械学習モデルに判断を寄せることでルールベースへの依存を少なくしていった
        * 機械学習で使っているデータは多分にルールベースの影響を受けているのでリスクを抑えるために徐々に不要なロジックを削除していった
    * ルールベースでは実装が難しかったデータでも機械学習モデルの特徴量には比較的容易に組み込むことができるので多様な行動データを扱うことが可能
    * 機械学習を用いる大きなメリットのひとつとして予測を単一の実数値に落とし込むことができる点にあるので、予測の閾値を調整することで返済率や売上のようなトレードオフの関係にあるKPIを事業の状況にあわせて柔軟にコントロールすることができるようになった
    * 機械学習導入から10ヶ月, サービス開始から2年で当初の事業目標を達成
* 機械学習パイプラインは最初はリリースを優先して大部分を手動での運用でカバーして必要なところから徐々に整備していった

##### 技術
* Go
* PostgreSQL
* Python (scikit-learn, LightGBM etc)
* SageMaker
* BigQuery
* Step Functions
* ECS/Fargate
* Cloud Dataflow
* Elasticsearch
* MLflow
* Embulk, Digdag

    
### iemo株式会社 (2014.08 - 2017.06)
```
住まい/インテリアのメディアでバックエンドや検索, 機械学習を活用した開発に従事
```
#### 検索基盤の整備
##### 背景/課題
* 全文検索にGroongaが使われていたが、ほぼメンテナンスがされておらず冗長化もされていなかった
* 仕様を詳しく把握しているエンジニアがいなかった為チューニングや機能追加が困難な状況だった
* 単純なN-gramによる検索で検索結果が雑多になっておりユーザが求める記事に到達することが困難であった
* インデックスの更新がバッチ処理で行われており記事が更新されてから検索に反映されるまでに時間がかかっていた

##### 担当
* 検索基盤の構築とそれを用いたバックエンドの機能開発

##### 実績
* 検索基盤をElasticsearchでリプレイスし形態素解析によるトークナイザの追加とチューニング
    * 検索結果からの離脱率: 25.28% -> 15.40%
    * 検索後記事に辿り着くまでのページ数: 5.25 -> 2.39
* 形態素解析の辞書, シノニムの整備及びメンテナンス用の管理画面の開発
* 記事更新時にジョブキューを用いて非同期にインデックスを更新
* 記事検索以外へ応用した機能開発
    * 関連記事などのコンテンツベースでのレコメンデーションによる回遊率の改善
    * 形態素解析, TF-IDFを利用した自動タグ付け
    * カテゴリ毎のトピック抽出を用いた導線の強化
    
##### 工夫した点
* 記事のコンテンツだけではなく画像のリンク切れや文字数のような記事のクォリティの指標をを検索に反映
* インテリアや雑貨などは次々と新語が生まれてくるため、社内ユーザの場合は記事検索画面で検索クエリと形態素解析の結果を確認できるようにして正しく認識されない単語をワンクリックで辞書登録できるようにした

##### 技術
* Elasticsearch
* SQS
* Ruby on Rails
* MySQL


#### サイト構造のリニューアル
##### 背景/課題
* サービス開始から1年以上経過し、記事が雑多になり既存のカテゴリ (インテリア, 家具 etc) の枠組みでは対応できなくなってきていた
    * カテゴリ内の統一性の無さによるユーザビリティの低下, メディアの世界観の破綻
* 記事のタグはメンテナンスされておらず、ひとつもタグがついていなかったり内容にそぐわないタグが設定されていた
* 無理にSEOを考慮したその場しのぎの設計になっておりカテゴリ/タグの構造が歪になっていた (SEOの観点からはサイトがツリー構造になっていることが重要な要素となっている)
    * カテゴリ/タグのツリー構造において親が子の概念を包含していなかったり、粒度が揃っていなかったりした
    * ツリーのリーフノードに記事がひとつも存在しないものがある
    * タグが特定のカテゴリ配下に紐付いてしまっていたりしてカテゴリとタグの役割が明確でない

##### 担当
* ユーザが求めている情報に素早くリーチできるようにすること、メディアのクォリティを担保すること、その為の課題の洗い出しと改善の実行

##### 実績
* 3万件の記事をチェックし既存の記事郡に必要なカテゴリの洗い出しを実施
    * 1階層8区分だったカテゴリを2階層46区分へ拡張
* 新しいカテゴリに合わせて記事を適切なカテゴリに修正
    * カテゴリ修正用の管理画面を用意し、アルバイトを1人採用して2人で2ヶ月程度かけてすべての記事のカテゴリ修正を実施
* 記事から自動でタグが付けられるようにした
    * Elasticsearchを使って記事の内容を形態素解析しTF-IDFで重要語を抽出
* 新しいカテゴリ/タグの構造に合わせてUIをリニューアル
    * カテゴリ内のテーマの凝集度が高まることによる視認性の向上
    * 子階層へのドリルダウンや関連キーワードといった導線強化による回遊性の向上

##### 工夫した点
* カテゴリの定義や修正作業は関わる人が多いと基準を統一することが困難であるであると考えたので少人数で常に認識を合わせながら進めた
    * カテゴリの基準を固めることができた段階で機械学習による自動カテゴリ分類の開発と並行して修正作業を進めることで工数を大幅に削減した
* カテゴリ/タグの階層構造は以下のような設計で整理し再構築することでSEOとUXの双方の改善を実現した
    * カテゴリは2階層で構成され、各カテゴリはMECEとなり唯一の親を持つ
    * タグは特定のカテゴリに依存しない汎用的なものとして位置づけ階層の数に制限はない
    * カテゴリ配下にタグを自由に配置できるようにし、タグの親カテゴリは複数持たせることができるようにした

##### 技術
* Ruby on Rails
* MySQL
* Elasticsearch

#### 機械学習を用いた記事の自動カテゴリ分類
##### 背景/課題
* 上記サイト構造のリニューアルにおいてすべての記事を人手で修正することは大変であったこと、またリニューアル後カテゴリが細分化されることで執筆者がどのカテゴリを設定すればよいのか判断が困難になることが予想された
* 個々人の判断に委ねるとまた雑多な状態になってしまうリスクがあった

##### 担当
* 機械学習モデルの開発
* 推論APIサーバの構築
* 記事作成CMSとのインテグレーション

##### 実績
* 記事のカテゴリ分類を行う機械学習モデルの開発
	* カテゴリ毎に特徴語を抽出しLSIで次元削減した特徴量で多クラス分類 (ロジスティック回帰)
* 記事全文をリクエストすることで各カテゴリの所属確率を推論するAPIサーバを構築
* 記事保存時に推論APIから返却された結果をもとに自動でカテゴリを設定できるようにした
    
##### 工夫した点
* 機械学習モデルの予測確率が曖昧なサンプル (Uncertainty Sampling) を優先的に教師データに追加する能動学習によって効率的に教師データのアノテーションを行った
* どのカテゴリの予測確率も閾値を超えなかった場合は「その他」カテゴリを設定するようにした
    * これら判定された記事はスパム記事が多く副次的にそのような記事を除外することができるようになった

##### 技術
* Ruby on Rails
* MySQL
* Python (scikit-learn, Gensim etc)
* Elasticsearch

### 株式会社ベネフィット・ワン (2008.04 - 2014.06)
```
福利厚生代行事業会社にて新規事業の立ち上げやシステムリニューアル, 業務システムの開発にPMとして従事
```

##### 主な実績
* ソフトバンクとの協業によるB2C向け優待サービスの立ち上げ
    * B2Bで提供していた自社の福利厚生サービスを携帯電話やインターネット回線の個人顧客向けに付帯サービスとして提供 (WEB・Androidアプリ)
    * APIの設計 (入退会 / 認証 / 通知 / 会員情報取得)
    * バッチ処理の設計(会員データ更新)及びステータス更新に伴う会員証発送などの業務フロー構築
* インセンティブポイントプログラムASPサービスリニューアル
    * 分散し非効率であった社内システム及び運用を各事業部門からヒアリングのもと全社的な業務フローを構築
    * 個社別のカスタマイズを洗い出し, 統合化指針の検討・決定
    * UIリニューアル
* グルメクーポンサイトリニューアル
    * Ruby on Railsで稼働していた既存サービスをJavaで再構築
    * 分散していた社内管理システムの統合, UIリニューアル

